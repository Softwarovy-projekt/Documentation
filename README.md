# CILOSTAZOL

CILOSTAZOL is an interpreter of a subset of the *Common Intermediate Language* - *CIL* using the *GraalVM* platform and
the *Truffle* framework. This project is a continuation of the *BACIL*
project [[1]](https://dspace.cuni.cz/handle/20.500.11956/176026). BACIL was developed as a Bachelor's Thesis on the
faculty of Mathematics and Physics of the Charles University in Prague. BACIL proved that CIL interpreter of written
using Truffle and GraalVM is not only possible but also quiet performant. Author of the thesis Jan Gocník compared BACIL
to other CIL interpreters that varied in approach to interpretation and performed several benchmarks which showed very
small performance decrease in comparison to the official .NET runtime. The goal of this project is to improve the BACIL
interpreter and to provide a better support for the CIL language.

Even though CIL is generated by multiple languages (C#, F#, VisualBasic), each one has its specific use-cases and
edge-cases.
In theory, it shouldn't matter what language emits the CIL code being interpreted, but some details might vary.
For testing and development purposes, we have decided to use C# mainly for two reasons.
Firstly, it was used for BACIL already.
Secondly, all team members are familiar with it not only on the level of the language itself but also in some aspects
on the level of the .NET runtime and the CIL itself.

## Content

- [CILOSTAZOL](#cilostazol)
  - [Content](#content)
  - [Existing technologies](#existing-technologies)
    - [GraalVM](#graalvm)
    - [Truffle framework](#truffle-framework)
    - [.NET](#net)
      - [Type system](#type-system)
      - [Value semantics](#value-semantics)
      - [String](#string)
      - [Managed pointers](#managed-pointers)
      - [Arrays](#arrays)
    - [BACIL](#bacil)
      - [Parser](#parser)
      - [Type system](#type-system-1)
      - [Runtime](#runtime)
    - [Espresso](#espresso)
  - [Problem analysis](#problem-analysis)
    - [CIL vs. Bytecode](#cil-vs-bytecode)
    - [BACIL](#bacil-1)
    - [Espresso](#espresso-1)
    - [Multi-dimensional arrays](#multi-dimensional-arrays)
    - [Internal calls](#internal-calls)
  - [Developer documentation](#developer-documentation)
    - [Parser](#parser-1)
      - [Low-level parser](#low-level-parser)
      - [Symbol factories](#symbol-factories)
    - [Type system](#type-system-2)
      - [Symbols](#symbols)
      - [Generics](#generics)
      - [Static object model](#static-object-model)
      - [String](#string-1)
      - [Arrays](#arrays-1)
    - [Interpreter](#interpreter)
      - [CIL interpretation](#cil-interpretation)
      - [Type resolution](#type-resolution)
      - [Exception handling](#exception-handling)
      - [Static analysis](#static-analysis)
      - [Stub methods and STDLIB](#stub-methods-and-stdlib)
      - [Nodeization](#nodeization)
      - [OSR](#osr)
    - [Launcher](#launcher)
  - [Tests](#tests)
    - [Own tests](#own-tests)
      - [Test from dll](#test-from-dll)
      - [Test from code](#test-from-code)
      - [Test from file](#test-from-file)
    - [Pipeline](#pipeline)
    - [Benchmark game](#benchmark-game)
      - [Benchmarking methodology](#benchmarking-methodology)
      - [Benchmarking script](#benchmarking-script)
      - [Results](#results)
  - [Development process](#development-process)
  - [Feature improvements](#feature-improvements)
  - [Conclusion](#conclusion)
  - [Appendix](#appendix)
    - [Overview of promised features](#overview-of-promised-features)
    - [List of supported opcodes](#list-of-supported-opcodes)
    - [User guide](#user-guide)
      - [Prerequisites](#prerequisites)
      - [Running CILOSTAZOL](#running-cilostazol)
      - [Running benchmarks](#running-benchmarks)


## Existing technologies

In the following chapter, we will describe high-level technologies we used in this project as well as existing solution
for CIL interpretation—BACIL that we've decided to build on.

### GraalVM

GraalVM is a high-performance java virtual machine which is itself implemented in Java. This virtual machine aims to
accelerate execution of java applications and other JVM based languages as well as other languages such as JavaScript,
Ruby, and Python thanks to the Truffle framework [[2]](https://github.com/oracle/graal).

The main advantages of this virtual machine as demonstrated at the discontinued course completed by all members of the
team
*NSWI176 - Practical Dynamic
Compilation* [[3]](https://is.cuni.cz/studium/predmety/index.php?id=1a2b9c4c601830def5e8fe1d818e0444&tid=&do=predmet&kod=NSWI176&skr=2021)
and its replacement *NSWI176 - Virtual Machines and Managed
Runtimes* [[4]](https://is.cuni.cz/studium/predmety/index.php?id=1a2b9c4c601830def5e8fe1d818e0444&tid=&do=predmet&kod=NPRG076&skr=2022)
are:

- fast startup time,
- low-resource usage,
- improved security.

GraalVM compiles Java applications ahead of time into standalone binaries which are naturally smaller, require fewer
resources, and according to the official GraalVM documentation [[5]](https://www.graalvm.org/latest/docs/introduction/)
are up to a 100 times faster to start. We witnessed this behaviour during the course mentioned above.

GraalVM also provides support for many useful tools such as *Ideal Graph
Visualizer* [[6]](https://www.graalvm.org/latest/tools/igv/) which can be used to visualise the compilation process of a
Java application in a graph form. This tool was also showcased during the course mentioned above.

For the purpose of this project, we used GraalVM a platform.
Utilising the Truffle language implementation framework to
provide hints to the GraalVM compiler that served as a JIT [[7]](https://en.wikipedia.org/wiki/Just-in-time_compilation)
and finally the GraalVM virtual machine and JDK implementation to execute the program.
The nomenclature is a little confusing as the term *GraalVM* is used interchangeably to refer to the virtual machine
itself as well as the platform
consisting or even the Truffle framework.
We will try to shed a bit of light on this problem with the following
relationship diagram.

```
GraalVM
├── GraalVM Compiler
└── GraalVM SDK
    └── Truffle framework
        └── Truffle languages
```

When the work on this project started, there were two GraalVM distributions.
GraalVM Community Edition,* which was open-source and *GraalVM Enterprise Edition*.
At the time of writing, there is only one edition of GraalVM which was
announced on the 13th of June 2023 [[8]](https://blogs.oracle.com/java/post/graalvm-free-license).
With that being said,
this project was developed using the *GraalVM Enterprise Edition*.

### Truffle framework

The Truffle language implementation framework also referred to just as Truffle is a framework utilising the GraalVM SDK
which helps with the implementation of so-called *guest languages* for the GraalVM.
Such guest languages include Python, Ruby, JavaScript, R and many others.
This framework also helps with the creation of tools such as the Ideal Graph Visualiser.
We only used this framework for the guest language implementation.

As a good entry point to get familiar with the framework, maintainers have prepared
*SimpleLanguage* [[9]](https://github.com/graalvm/simplelanguage) and a
*SimpleTool* [[10]](https://github.com/graalvm/simpletool). These are low-code projects demonstrating the basic and in
some cases, advanced features of the framework. We have used the *SimpleLanguage* as a study reference several times.

The Framework provides a useful API that we can use to provide hints to the GraalVM compiler.
These hints are then used to improve the performance of the interpreted language.
Namely, it allows us to hint for a better and speculative partial evaluation of the compiled code.
Some of the annotations we have used are:

- `CompilationFinal`,
- `TruffleBoundary`,
- `TransferToInterpreter`,
- `TransferToInterpreterAndInvalidate`...

Thanks to these annotations, we are able to tell the compiler that something may have become a constant, and it should
be treated as one.
Since partial evaluation is well described both in the project we are building upon - BACIL this introductory tutorial
of how to implement a new language with
Truffle [[11]](https://docs.oracle.com/en/graalvm/enterprise/20/docs/graalvm-as-a-platform/language-implementation-framework/LanguageTutorial/#implementing-a-new-language-with-truffle)
provided by Oracle, we will not explore it into every detail.
However, for clarity and completeness, we will provide a simple example which is explained in both sources in various
forms.

In the following pseudocode we will demonstrate usage of `CompilationFinal` and `transferToInterpreterAndInvalidate`.
Assume that the cache is initialized with some interesting values.

```java
@CompilationFinal(dimensions = 1)
Object[] cache = new Object[32];

Object readCache(int index) {
    return cache[index];
}

void writeCache(int index, Object value) {
    transferToInterpreterAndInvalidate();
    cache[index] = value;
    guard = false;
}
```

Using the `CompilationFinal(dimensions = 1)` directive we hint the compiler that this array is constant on the first
dimension—all its elements are constants. Therefore, once we are, for example, in some hot loop where reads from the
cache are frequent and compilation occurs, the compiler will consider all elements of the array to be constants and the
instructions generated might be optimized. Once we write into the cache we call `transferToInterpreterAndInvalidate()`
transfers from the compiled code back into an interpreter and invalidates the compiled code.

The fact that using Truffle's API to provide hints to the compiler is a viable approach is already proved
by [BACIL](#bacil). In the thesis author provides several benchmark results and discussions comparing the performance of
BACIL to the .NET runtime as well as other implementation implemented by Patrick
Hagmüller [[12]](https://epub.jku.at/obvulihs/content/titleinfo/5473678).

### .NET

The .NET is similar to GraalVM, a software development platform that provides runtime, standard libraries, and an
SDK.
Just like with GraalVM, the .NET nomenclature is tangled in history as the term .NET is used to refer to all .NET
Standard, .NET Core, .NET Framework, etc.

In this project, we will only care about some parts of the .NET platform. All .NET languages are compiled into a
bytecode
similarly to Java. This bytecode is called *Common Intermediate Language* or *CIL* for short. This bytecode is then
interpreted by a *Common Language Runtime* or *CLR*. This is the part we will be replacing with GraalVM.

BACIL already implements the raw core of the interpreter and the bytecode parser but completely ignores other parts
which we will try to handle.
It is worth noting some details from the *Common Language Infrastructure* - *CLI* that be useful and are important for
us to be able to extend BACIL.
CLI is a
standard [[13]](https://www.ecma-international.org/publications-and-standards/standards/ecma-335/) that provides
specification for executable code and the environment in which it runs.

#### Type system

CLI specifies two kinds of entities **value types** and **reference types**. Values are simple bit patterns that we
have to interpret in a correct way. This might be integer types or floating point types. Objects on the other hand are
self-typing. That means that the type information is stored in its representation. On the graph taken from the ECMA
standard we can see a diagram of the type system.

> Diagram from of type entities from the CLI standard. 
> 
> ![CLI type system](./img/CLI_type_system.png)

Note that even though C# has both classes and structs, they are not distinguished in the CLI as a value and reference
type. In fact, a common misconception is that structs are of a value type kind.

#### Value semantics

CLI specifies difference between value and reference semantics. Valuable types should be passed by value unless boxed.
We
have to make sure that we handle all value types in such way. There are specialised instructions for most of the value
types. For example `ldc.i4.0` pushes a 32-bit integer value of 0 onto the stack. `ldc.r8` pushes a 64-bit floating point
value of 0 onto the stack.

As described in partition *II. part 13. Semantics of value types* of the CLI
standard [[14]](https://www.ecma-international.org/publications-and-standards/standards/ecma-335/) all value types shall
have their *boxed form*. They must have a direct base type of either `System.ValueType` or `System.Enum`. There are
special ways to initialize value types and how to handle their `null` values. Value types can also have methods and
fields, those are only relevant in their boxed form. All those constraints mean that we have to keep track of value
types.

#### String

String is a built-in reference type in the CLI. It may seem that we can treat strings like an ordinary object, but
CLI exposes several differences between objects and strings.
Strings have specialized instructions for installations.
Object is instantiated using the `NEWOBJ` op code, yet the string uses the `LDSTR` opcode. After that, we may treat it
like an ordinary object. We will have to be able to parse and interpret the source code if the standard library where
the `String` class is defined. 
The biggest difference is data representation and its description in CIL metadata where we can find that the object consists of two fields - length(`int`) and a first char(`char`).
Although .NET runtime treats the `char` as a `char*` in the implementation and the array of bytes representing string is embedded into the object itself.

#### Managed pointers

One of the supported types in the CLI are managed pointers. They are points to the interior of an object. Managed
pointers can point to a field within an object, element within an array or even to variables on stack or static
variables.

#### Arrays

Another special type is an array. Arrays are divided into two categories, the naming of which is once again very messy.
Sometimes they are called *vectors* and *non-vectors* and sometimes *vectors* and *arrays* with the term array
referencing to
either of them. Both have different semantics and both have to be handled differently.

- Vectors are single-dimension with zero lower bound and have direct CIL instruction support. That is that there is a
  special instruction for creating a vector - `NEWARR`, series of `LDELEM` instructions for loading element values and
  mirrored series of `STELEM` instructions for storing element values. Similarly to the string type we will have to
  parse and interpret the source code of the standard library where the `Array` class is defined.
    - In C# code vectors represent standard array `int[] array`.
- Arrays, or non-vectors are all other types of arrays. In practice, that means that they are multidimensional arrays
  or arrays with a rank bigger than one. Classes for those arrays are created by the *Virtual Execution System* - *VES*.
  The semantics are as with an ordinary object. The constructor is called using the `NEWOBJ` instruction and the
  elements are accessed via method calls `Get` and `Set` on the generated class.
    - In C# code arrays represent `int[,] array`.

Note that *jagged-arrays* - `int[][]` have no special support in the CLI. They are simply vectors, the elements of which
are vectors or jagged-arrays again.

### BACIL

As mentioned at the beginning, this project is based on the BACIL project. BACIL is a bytecode interpreter for a subset
of CLI. It provides parser implementation that is able to parse compiled bytecode and read all the metadata and
implements functionality for the majority of the opcodes.

#### Parser

The foundation of the parser is very well described in the
thesis [[15]](https://dspace.cuni.cz/handle/20.500.11956/176026) henceforth we will not describe it here in much
detail even though it is a vital part of BACIL. The parser allows us to read compiled bytecode and extract required
metadata from it. The metadata is described in the *Partition II Metadata* of the CLI standard. It consists of a set of
tables such as MethodDefTable, TypeDefTable, TypeRefTable etc. Each table contains metadata of some entity. For example,
the TypeDefTable contains metadata of all types defined in the assembly. This metadata contains among others, name,
indices into other tables with methods, fields etc., flags about visibility and other properties.

Even though we have discussed the state of BACIL with the author prior to the implementation part of this project, it turned out that the parser was
at some points vastly incomplete for our needs along with some bugs that naturally occur in such a big project. However,
the foundation was good enough to reuse it and extend it to our needs. This had brought a big dent into our plans and
delayed several parts of the project.

#### Type system

Even though BACIL was able to interpret seemingly complex code, it was not suited for further extension at all. There
was
virtually no type system that would allow us to support generic types, arrays, strings, and other types. BACIL even
included some simplifications that made it impossible to support other languages other than C#. One of such
simplifications was the absence of modules.

> Diagram from of assembly entities from the CLI standard.
> 
> ![CLI_assembly_diagram](./img/CLI_assembly_diagram.png)

On this figure we can see a diagram of an assembly as described in the CLI standard. According to the CLI standard,
*assembly* is a configured set of loadable code modules and other resources that together implement a unit o
functionality. And *module* is a single file containing content that can be executed by the VES.

> Diagram of assembly entities as implemented in BACIL. 
> 
> ![BACIL_assembly_diagram](./img/BACIL_assembly_diagram.png)

Compare it to this figure visualising the assembly as implemented in BACIL. In practice, BACIL only allows one module
per
assembly. Even though it is rarely the case that there is more than one module per assembly, it is still a valid
scenario. This may be reminiscent of the Simple Language implementation as some vital parts of CLI follow the naming
convention of the Simple Language as opposed to CLI. One such example is the `BACILComponent` class which represents
the `Assembly` or alternatively `Module` in CLI.

#### Runtime

BACIL runtime is combined with parser which is making those two otherwise independent modules tightly coupled.
Therefore, we have decided to untie the dependencies and create parser standalone. Due to lack of extendability of the
type system, we have decided to implement everything from scratch while reusing the parser and as much runtime as
possible.

### Espresso

Espresso is a Java bytecode interpreter for the GraalVM [[16]](https://github.com/oracle/graal/tree/master/espresso).
This is a highly influential bytecode interpretation which incorporates most of the feature Truffle offers. In the
beginning, this was our and visibly also BACIL's inspiration. However, as the project progressed, we have found out that
due to differences between Java and C#, most importantly its compiled bytecode alternatives, it is better to take
inspiration from Roslyn. Problems are in more detail described in the following chapter.

## Problem analysis

Although Espresso showed that interpreting bytecode can be done by using the Truffle framework, we encountered several problems regarding the architecture of CIL and BACIL as a start project. In this section, we will mention the most significant ones.

### CIL vs. Bytecode

There are arithmetic CIL instructions working with different types of operands.
Although the high-level view on the instructions can look the same (e.g., adding two numbers),
there is a difference between adding two floats and adding two integers at the low-level layer.
So when we interpret values on the stack, we have to know their types to choose the correct version of the instruction.

Take a look at the two following code snippets computing addition of integers, floats respectively, with their respective CIL generated by sharplab.io [[17]](https://sharplab.io/#v2:C4LglgNgNAJiDUAfAZhA9gQ2AAg9gvNgEwCMA3ALABQqmOARgceddbVtgMZN7zb1kgA=):
```csharp
/*
IL_0000: ldc.i4.s 21
IL_0002: stloc.0
IL_0003: ldc.i4.s 21
IL_0005: stloc.1
IL_0006: ldloc.0
IL_0007: ldloc.1
IL_0008: add
IL_0009: stloc.2
*/
int a = 21;
int b = 21;

int c = a + b;
```

```csharp
/*
IL_0000: ldc.r4 21
IL_0005: stloc.0
IL_0006: ldc.r4 21
IL_000b: stloc.1
IL_000c: ldloc.0
IL_000d: ldloc.1
IL_000e: add
IL_000f: stloc.2
*/
float a = 21;
flaot b = 21;

flaot c = a + b;
```
As we know from the previous chapter value types such as `int` and `float` are of a value type kind which means it is just a series of bytes, and it is the responsibility of VES to interpret them correctly. There are two different opcodes for loading `int` and `float` onto the stack - `ldc.i4.s` and `ldc.r4` respectively. However, the add instruction is exactly the same.

Here are equivalent code snippets in Java and its bytecode as generated by IntelliJ:
```java
/*
L0
  LINENUMBER 3 L0
  BIPUSH 21
  ISTORE 1
L1
  LINENUMBER 4 L1
  BIPUSH 21
  ISTORE 2
L2
  LINENUMBER 6 L2
  ILOAD 1
  ILOAD 2
  IADD
  ISTORE 3
*/
int a = 21;
int b = 21;

int c = a + b;
```
```java
/*
L0
  LINENUMBER 3 L0
  LDC 21.0
  FSTORE 1
L1
  LINENUMBER 4 L1
  LDC 21.0
  FSTORE 2
L2
  LINENUMBER 6 L2
  FLOAD 1
  FLOAD 2
  FADD
  FSTORE 3
*/
float a = 21;
float b = 21;

float c = a + b;
```

When we look at the equivalent instructions in bytecode, the instructions themselves differ between integer addition and float addition. Loads for integers and floats are differentiated similarly as in the CIL however we can see that the `ADD` instructions carries a prefix (`IADD` and `FADD`) depending on what types it operates on which is not the case in CIL.


We don't want to investigate the type of operands in the runtime since we're interpreting statically-typed language. For this reason, we need to create a static analysis of the CIL before we execute it in order to interpret the instructions correctly.

We also have a different type system.
We need to deal with `struct` which has value semantics in comparison with `class` with reference semantics. Some opcodes even explicitly require different behaviour when dealing with value types.

The main challenge is supporting generics that are not presented in bytecode.
We can't get inspiration from Espresso or BACIL since bytecode does not contain it and BACIL doesn't support generics either.
However, we can look at metadata representation in the Roslyn compiler and adjust it to work with partial evaluation.

### BACIL

CILOSTAZOL takes BACIL and tries to extend it.
However, there are many difficulties, which make it difficult or even impossible at times.
The biggest problem was the parser, which we thought we would use in our implementation as is.
We had to add a large part of parsing metadata to be able to work with generics, exception handling, and interfaces.
As we mention later in the text, the parser can be divided into two parts.
The first one we call a low-level parser, which was taken from BACIL.
The rest of the parser had to be reimplemented.

BACIL type system is restricted to a small part of CIL and can't be extended to support generics and other advanced
constructs.
Therefore, a completely new type system has to be created.

BACIL's a nonstandard way of treating stack also should be changed
to use standard `VirtualFrame` which offers us broader API for working with it.
The previous problem described between bytecode and CIL,
where Java bytecode has specialised instructions for different types of operands and CIL does not,
is handled in a peculiar way in BACIL.
It keeps two different stacks.
One for references and one for value types that only support primitives.
In addition, the primitives are all saved in a java `long` type
and the actually type is determined by mirrored `Type` object on the reference stack.
We will resolve this problem using static analysis of the opcodes.

We also have to change the execution node of BACIL since it doesn't handle exceptions and add *On Stack Replacement* - [*OSR*](#osr).

The last change to be added is the *Static Object Model* - [*SOM*](#static-object-model). OSR provides an abstraction to represent layout of objects that do not change their properties. That is handled differently in BACIL as well.

In conclusion, we think that BACIL is so tangled and tightly coupled that it is almost impossible to extend it to support our defined
features.
Because of the problems described above, we have decided to reimplement the whole interpreter and use only the common parts of BACIL as a foundation.

### Espresso

Although we got a lot of inspirations from Espresso, differences between CIL and bytecode are significant (generics, untyped instructions).
So in the case of the type system, we got inspiration from Roslyn and adjusted it to be partially evaluation-friendly.
In fact, we first tried to use Espresso's approach,
which proved to be difficult to work with and extend to the needs of CIL.
The main inspiration from Roslyn was in the type system, its generic type support, and the way it handles exceptions.
In the case of untyped instructions, we created our own static analysis which determined the type of instructions
statically.

### Multi-dimensional arrays

In section [.NET](#net) we mentioned that CIL supports vectors—single dimension zero based arrays and multidimensional arrays. Multidimensional arrays do not have any classes in the standard library that we could easily interpret. Classes for non-vector arrays are generated on demand with the help of some functions from the `System.Array` class. We can either generate the classes on demand or implement our own version of non-vector arrays. The first option would require us to either generate correct bytecode that would then be parsed and continue with the rest of the type system as is. Or we could handle specific scenarios in every place where multidimensional arrays can occur. The latter would bring unwanted complexity to the codebase and is therefore out of the question. The first one is very tedious with generating correct and valid bytecode.

After inspecting the functionality that non-vector arrays are supposed to provide and the helper methods from `System.Array` we decided to implement our own version of non-vector array class in C# that we would then interpret. Elements of this array would follow the CLI specification and be stored in a single dimension array. In this way, we will be able to use the same type system and other existing functionalities without additional overhead. 

It must be said that none of the mentioned approaches works with memory in an efficient way, and we can not expect to have the same performance as in .NET. However, we believe that this is a reasonable trade-off for the simplicity of the implementation.

### Internal calls

Some of the functionality will still not be supported but are required for a smooth development process. For example internal calls or methods that use unsafe code which is out of scope of this project. 

A good example is the method `System.Console.WriteLine` which prints to the output. Printing allows us to create automated tests that can be used to verify the correctness of the interpreter. However we will not support all the functionality required for this method's execution.

BACIL already provides a way to handle such scenarios which is to implement stud methods with our own implementation. We use this approach as well.

## Developer documentation

The solution consists of many parts responsible for distinct purposes.
We provide brief descriptions of them to make the navigation between them easier.  
The project solution contains four modules:

- **cil-parser** - It contains a low-level parser of CIL metadata which is not dependent on the rest of the interpreter.
  It provides API for navigating through the CIL metadata tables.
- **language** - This is the core module of the interpreter. It contains a definition of CIL symbols like *class* or *method*, an
  object model holding user data, nodes representing CIL code, factories using the mentioned parser yielding the
  symbols, static analysis of types, a context holding several caches, and tests verifying metadata representation.
- **launcher** - It is a launcher of the interpreted language.
- **tests** - It contains a custom framework for testing end-to-end tests taking *.cs* sources, compiling them,
  executing them in the interpreter, and asserting the results.

> Overview of CILOSTAZOL project architecture
>
> ![architecture_overview](./img/CILOSTAZOL.png)

Although the detailed description of interpreting CIL will be given later, we also provide a brief overview of the
pipeline to make understanding each part of the process easier.
We compute everything lazily in CILOSTAZOL, however, we use the arrows in the picture in the opposite direction to
indicate data flow.
Which means that when the request to execute CIL code arrives, we start to locate the required *.dll* files. Once found, we
use **symbol factories** to transform the files into application data. The factories use **low-level parser** to obtain
meta tables and streams.
Then, it starts to assemble them into symbols that are used during the interpretation.
Because this process can take a long time, we extensively use caches located in the context. Each symbol is therefore materialized only once.
Since we have the necessary symbols, we find an assembly entry point and make the execution node execute it.
The execution node is created by a custom method, which collects necessary information about the method.
The execution node cares about many things. It uses our static analysis, which is made on the first execution of the
method to determine correct versions of CIL opcodes, prepares the frame, performs nodeization on heavily used 
instructions, and handles exceptions.
During the evaluation of the code, there is a need to resolve symbols referred in metadata.
**SymbolResolver** was made to provide a unified API for it in order to make sure every resolved symbol gets properly cached.
**GuestAllocator** is used to create objects based on symbols.
In the end, because some methods from the standard library use unsafe code or other constructs which are not supported
by the CILOSTAZOL, we provide a custom implementation of commonly used methods used in our benchmarks to be able to use
them.

> Overview of .dll pipeline
>
> ![pipeline](./img/Pipeline.png)

### Parser

The parser can be divided into two parts.
We call the first part low-level parser which handles navigation between CIL meta tables and streams. This part consists mostly of data classes that correspond to the tables as defined in the ECMA-335 standard.

The second part is contained in dedicated symbol factories focusing on a small part of the metadata.

#### Low-level parser

We took the low-level parser from the BACIL project and transformed it into a separated module since it is independent
of the remaining parts of the interpreter.
Because metadata contains lots of tables that would behave in a similar way, the code generator was used to generate
Java classes according to simpler tables description given in simple format. This was done already in BACIL.
When the generator is run, a dedicated class for each table is created.
The table consists of rows describing a part of the metadata.
The rows are implemented as smart pointers using the iterator pattern for better usage.
The columns can be constants or other pointers to different tables or streams.
Streams contain different kinds of signatures describing other metadata or string constants.
These signatures have to be implemented manually because of harder parsing constraints.
The signatures are part of the low-level parser as well.

We noticed some bugs in the table descriptions, which we fixed according to the ECMA specification.
There was also an issue regarding the low-level interpretation of indices, which was fixed as well.
In the end, we reimplemented the signatures since the former implementation just parsed necessary part of the information required by BACIL. We implemented parsing for all features and not only those that we require. Therefore, there are some fields and methods that might not be used anywhere.

#### Symbol factories

The symbol factories are responsible for interpreting data obtained from the low-level parser and transforming them into
symbols which we describe later.
We don't see a parallel part in the BACIL because it was strongly connected with BACIL's type system.
We think that this architecture was wrong because of future maintainability and code extensibility.
We separated symbol representation and creation by providing factories for each type of symbol. 
Our architecture closely follows the ECMA specification and is inspired by Roslyn implementation, which can be a good sign for correctness, extensibility and maintainability. The nomenclature of the symbols also follows the ECMA specification and makes it easier to understand the code.

Because we don't need to parse every method and class in the assembly to evaluate simple code, we use lazy evaluation of
metadata, which would take a long time.
For example, we parse only referenced methods.

For performance reasons, we cache already created symbols in the context and reuse them when it is referenced again in
the CIL.
We have several types of caches for different types of symbols.
The context contains separated caches for generic types, instantiated generic types, arrays, and generic method
instantiations.
`NamedTypeSymbol`s have caches for defined methods and fields.
Because of the compressed design of CIL metadata, we also use several reverse indices in `ModuleSymbol` to help resolve symbols
from caches.
These indices are `MethodIndex` and `FieldIndex` respectively.
It is a tuple of an index and a method or field definition in a given module.
This is very helpful
because many of the opcodes provide row pointer to a field or a method
that is supposed to be called together with the opcode.
Take the `LDFLD` opcode as an example
which carries metadata token pointing to a `fieldref` or `fielddef` metadata table.
Each of these tables contains information about a specific field implementation.
Using the `FieldIndex` we can quickly query the parsed field without difficult materialization.
The same applies to `MethodIndex` and `call` opcode.
The use of those indices is an implementation detail hidden behind the API.

To be sure that we always use already cached symbols, we use `SymbolResolver` which is responsible for handling all
types of metadata references and returning appropriate symbols.
Since we use the `SymbolResolver` only, there is just one option, how the `NamedTypeSymbol`, `AssemblySymbol`,
or `MethodSymbol` is created. The context is the only one that calls further methods for creating these symbols when
it is not found in the caches. Except for non-instantiated methods, which are created lazily and cached in
the `NamedTypeSymbol`.  
More info about `SymbolResolver` can be found in the following [type system section](#type-system).

### Type system

In this section, we describe the system of symbols heavily used in CILOSTAZOL to represent CIL components. We also talk
about how CIL application data are represented during the runtime.

#### Symbols

Symbols can be divided into three categories:

- **Method-related symbols** - Red-colored symbols in the picture
- **Type-related symbols** - Yellow-colored symbols in the picture
- **.dll related symbols** - Blue-colored symbols in the picture

> Overview of symbols
>
> ![symbols](./img/TypeSystem.png)

All symbols have a common predecessor, `Symbol`.
For testing purposes, the symbol currently contains only one method used to get the `CILOSTAZOLContext`. The reason is
given in the tests section.

 - `TypeSymbol` contains several additional data related to types such as `SystemType` or `StackTypeKind`. This information is needed in order to correctly represent the type on stack and inside the constructed type (meaning `class`
or `struct`).
It is also required a predecessor of type, which can be used as an input into `TypeMap` used for generic types.
   This map is described in more detail later in the section about [generics](#generics).
It also provides an API for determining the assignability of CIL types.

 - `ReferenceTypeSymbol` represents managed pointers in CIL which consist of information about the actual location of the
pointed entity (local variable, argument, object field, or array element), and the actual type of pointed object.

 - `ArrayTypeSymbol` describes CIL arrays. We can consider this symbol as a special case of `NamedTypeSymbol` because it describes an array of rank one, but it also contains the type of the array's elements.

 - `MultidimensionalArrayTypeSymbol` is a special case of `ArrayTypeSymbol`. This array is used to distinguish between vector and non-vector arrays since both have completely different semantics. `MultidimensionalArrayTypeSymbol` exists to help navigate use the `MultidimensionalArray` implementation which serves the role of classes that would be otherwise generated in the runtime. 
   - The type is defined in the `CILOSTAZOLInternalImpl` C# solution. Whenever we encounter an array with rank bigger than one, we opt out to creating the `MultidimensionalArrayTypeSymbol` instead of the `ArrayTypeSymbol` and as a base we use the `MultidimensionalArray` implementation from the mentioned solution. This class contains the exact same methods that are needed to operate on those arrays. The following code snippet shows what opcodes are generated when dealing with multidimensional arrays.

```csharp
/*
IL_0000: ldc.i4.2
IL_0001: ldc.i4.5
IL_0002: newobj instance void int32[0..., 0...]::.ctor(int32, int32)
IL_0007: stloc.0
IL_0008: ldloc.0
IL_0009: ldc.i4.1
IL_000a: ldc.i4.2
IL_000b: ldc.i4.5
IL_000c: call instance void int32[0..., 0...]::Set(int32, int32, int32)
IL_0011: ldloc.0
IL_0012: ldc.i4.1
IL_0013: ldc.i4.2
IL_0014: call instance int32 int32[0..., 0...]::Get(int32, int32)
IL_0019: stloc.1
*/
int[,] a = new int[2,5];
a[1, 2] = 5;
var b = a[1, 2];
```
-
  - We can see call of an ordinary constructor that takes two indices. Writing and reading array elements is done via `Set` and `Get` (instead of `LDELEM` and `STELEM` opcodes as it is with vectors) methods on an instance of local variable at index 0 (`ldloc.0`).

  - Virtual methods are resolved in a way that we first look for override implementations in our instantiated type. In our case that would be `MultidimensionalArray`. The only thing that is left is to have implementation of `Set` and `Get` methods in the `MultidimensionalArray` class. From analysis of the `System.Array` type we can see that there are explicit implementations for 2D and 3D arrays. Arrays of higher dimensions are resolved using the variable number of arguments. The signature of such method simply contains an array of indices. To support higher dimensions, we would need to implement support for attributes. This is out of scope of this project. Our chosen approach of having one predefined class handling all dimensions would be insufficient, because variable number of arguments is only allowed as the last argument. However, the signature of `Set` method contains the value as the last parameter. This was an oversight during the analysis which happened partially due to incorrect understanding of how exactly does the generated array class looks like. We have decided to support only 2D and 3D arrays with a workaround to up to 5D arrays.

  - Note that the `MultidimensionalArray` implements all the necessary interfaces that a normal array should. To be completely correct we would have to extend the class by `System.Array` class which is not possible. The type is one of special types that can not be used as a base class. The reason is that it is a special type that is handled by the runtime. The same applies to `System.ValueType`, `System.Enum` or `System.Delegate` types. The multidimensional array is saved in a simple array with flattened indexation the same way it is done in the `GetFlattenedIndex` method in the `System.Array` which is used for exactly this purpose.

 - `NamedTypeSymbol` describes named types in CIL including generic ones. It consists of other symbols for fields or
methods. 
  - Note that even value types have their `NamedTypeSymbol` which is useful for their boxed variants.

 - `TypeParameterSymbol` serves as a placeholder for generic types. Before they are substituted with actual types, they are tracked as `TypeParameterSymbol`.

On the other side, we have `MethodSymbol` which can be executed.
The ancestors of that symbol are described in the [following section](#generics) about generics.
`MethodSymbol` consists of other method-specific symbols such as `ParameterSymbol`,
`ReturnSymbol` and `ExceptionHandlerSymbol`.
They usually contain some `TypeSymbol` which they represent.
This architecture makes handling methods much more clean and easy to navigate through.
For example method contains only exception handlers which are in the method
(`catch` clauses) and are extracted from metadata.

The last group of symbols represents high-level CIL containers.
`ModuleSymbol` is responsible for creating `TypeSymbols` defined locally.
`AssemblySymbol` is responsible for creating `TypeSymbols` defined in their modules.

#### Generics

The main challenge was dealing with generics.
We had to think of a mechanism for instantiating generic types.
We got inspiration from Roslyn and use the following observation.
Generic entities can be found in three states: opened, substituted, and constructed.
An entity is opened when it is generic and no instantiation has been done yet.
An entity can become substituted when it contains another entity (excluding type arguments) which is a type parameter
not belonging to the containing entity.
An entity becomes constructed when it is instantiated by types.

You can see an example of the substitution below.
```csharp
class A<Ta> 
{
  void Foo(Ta p1) {}   
}
class B<Tb> : A<Tb> {} // A<Tb>.Foo(Tb p1) is a substituted method.
```

This observation led to the creation of three types of method symbols. MethodSymbol represents an opened generic entity.
The `SubstitutedMethodSymbol` represents a substituted entity and the `ConstructedMethod` symbol represents the last
option.

We didn't make a `SubstituteNamedTypeSymbol` because we don't support nested classes but the principle is the same and its implementation should not be very difficult.

Instantiation of generic entities is done by `TypeMap`.
When we instantiate a type or method, we create a type map that maps type parameters to provided type arguments.
In the case of the substituted method, we provide this type map of a constructed defining type to
the `SubstitutedMethodSymbol`.
When we want to find out entities of constructed types of methods, we use this map to map the entities contained in the
map.

This approach allows us to create all open, substituted and constructed entities.

#### Static object model

Primitives are represented by Java primitives.
Although, we have to be careful during interpreting unsigned versions of CIL primitives since Java doesn't have an
equivalent for them.

We used Truffle API for creating static objects and created our own `StaticObject` with a field of `TypeSymbol` type
representing a reference to metadata symbol.
It allows us to implement virtual methods and other things described later.
We also created `StaticField` representing fields of a CIL object.

> Overview of data representation in CILOSTAZOL
>
> ![SOM](./img/SOM.png)

Data representation of classes and structs are the same in CILOSTAZOL.
We just treat them differently to save reference and value semantics.
There are two Truffle object shapes representing the instance and static part of a CIL object.
These shapes are lazily created based on metadata.
Each instance of `NamedTypeSymbol` has one field representing the static part of it of type `StaticObject` consisting of
static fields of the CIL type.
There is the important thing about caching the symbols since we have to have exactly up to one instance of `TypeSymbol`
representing CIL type.

When we want to create an instance of a named CIL type, we use the instance shape of that type.

The creation of arrays is simpler because there is a finite amount of array types (arrays with a primitive element type
and with reference element type).
So we have prepared their shapes in the context and just choose based on the element type.

Managed pointers are quite tricky because, according to ECMA standard, it pushes an address of the pointed object to the
stack.
This behavior is unachievable for us since we implement the interpreter in Java.
Instead of it, we have our own static objects containing the necessary components to access the pointed objects.
For example, for a managed pointer pointing to an element of an array, we create a static object instance containing the
index of the array and the array as fields.

#### String

`string` is represented differently in comparison with .NET.
.NET represents strings as a pair of the lengths of a byte array and the byte array representing the string.
Although, the array is embedded into the pair, which means that the string object length depends on the value inside
them for performance reasons.
This implementation is hidden in CIL metadata which describes `string` as an object with two fields of type `int`
and `char`.
We save the information about the fields and represent `string` as a static object with two fields of `int` and
an array of `char` types.

#### Arrays

There are single and multidimensional arrays in CIL.
We got inspiration from Espresso and represent them as a static object with one field containing a java array of a
particular type.
This representation allows us to determine arrays as objects in the rest of the code.
As described in the [type system](#type-system) section multidimensional array is stored as a row-major single-dimensional array inside `MultidimensionalArray` type which is equivalent to CIL.

### Interpreter

In this section, we describe execution of CIL code.
Once again, we were inspired by Espresso and used one node representing one CIL method.
However, we are using extra nodes for instructions like `CALL` or `VIRTCALL` in the process called nodeization in BACIL.
We removed custom handling of evaluation stack used in BACIL and replaced it by using Truffle `VirtualFrame`.
We added exception handling and OSR.
We also make static analysis of CIL code before the first run of each method to determine the correct versions of CIL
instructions.

#### CIL interpretation

As we mentioned before, we use typical `BytecodeNode` for interpreting CIL.
Besides the main loop in the node, we use the `CILOSTAZOLFrame` class responsible for manipulation with the frame.

> Overview of getting info about current types on the stack.
>
> ![types](./img/Frame.png)

We are using the static API of pushing and popping values in `VirtualFrame`.
Most of the time, an instruction type hints to us what kind of type will be pushed to the frame or popped from it.
Although, during the initializing frame, executing arithmetic instructions, or calling virtual methods, we don't know
the types of values which we work with.
In order to find it, there are three sources where we can get the info.
In the first situation, we use symbols contained in the defining method, which are able to give us which type is on the
frame.
In the second situation, we use results from the static analysis, which determines the type of arguments, which we will
work with.
And the last source is to use the stored `TypeSymbol` contained in `StaticObject` if it is a static object.

An interesting part of instruction interpretation is unsigned arithmetics.
Unfortunately, java doesn't have built-in unsigned primitive types.
So we had to implement it with the help of other Java standard library functions.

We also cache `string` literals in our `GuestAllocator` because they are immutable.

`struct`s are represented in the same way as classes which is inefficient in comparison with .NET where the `struct`s
are placed on the stack (if they can be placed there).
However, we didn't find a better way how to do this in Truffle.
We change the behavior of passing arguments, assignments etc. based on the `TypeSymbol` of the `StaticObject`.

#### Type resolution

> Overview of caches
>
> ![caches](./img/Cache.png)

We need to resolve referenced metadata during CIL interpretation frequently.
Although, there are many kinds of references that are resolved differently.
We choose a way to keep the related things together and introduced `SymbolResolver` which is used everywhere, where we
need to resolve `AssemblySymbol`, `TypeSymbol`, `MethodSymbol`, and `FieldSymbol`.
Internally, it uses `CILOSTAZOLContext` to determine the referenced symbol.
The context consists only necessary API for determining a symbol.
For example, when we want to resolve an instantiated generic type using context, we need to know its `TypeSymbol`
definition and its arguments.
Although, CIL code uses low-level metadata pointers to refer to these symbols.
So we move navigation through these pointers to the `SymbolResolver` and leave just the necessary API for resolution in
the context.

As we already mentioned, the context has caches of `TypeSymbol`s and is responsible for initiating a creation of a
requested `TypeSymbol`, if it is not presented in the cache.
This is done by custom methods of `AssemblySymbol` and `ModuleSymbol` which uses symbol factories.
The API is used only by context preventing the creation of more than one `TypeSymbol` of the same CIL type.

When we want to resolve a field or method symbol, the situation is harder.
For example, the reference can represent an index in the table of method definitions.
As we said previously, we cache methods belonging to a type in the instance of appropriate `NamedTypeSymbol`.
Unfortunately, the metadata describing a method doesn't contain a pointer to define the type.
This info is stored in the type definition.
So, at the start of parsing a new CIL module, we make indices of which method or field belongs to what type and then use
it to navigate `NamedTypeSymbol` defining these symbols.

#### Exception handling

There are two moments when an exception occurs.
Special instruction `THROW` or `RETHOW` is executed or an instruction itself throws an exception.
We handle both situations in CILOSTAZOL.
When `THROW` is called, we resolve the referenced type of the exception which should be thrown, wrap it into a
customized Java exception and throw it in the interpreter.
For the second situation, we sanitized places where the exception can be raised based on the standard and throw
appropriate exceptions as well.
Note that we don't collect info about stack trace and other data because it would complicate the code since it uses
unsupported features.

Handling is done by wrapping the main switch node by a `try-catch` block and catching our customized exception
containing the CIL exception.
If the exception occurred, we filter the table of exception handlers defined in `MethodSymbol` and jump to the
appropriate handler, if there is any.

#### Static analysis

The problem of not having typed instructions that do require the knowledge of types of its operands is solved by static analysis. When required the `StaticOpCodeAnalyser.analyseOpCodes()` is called and the static analysis is performed. The output is an array with types for each opcode that requires such information. The stack allows only limited set of types to be stored on it:
 - `int32`,
 - `int64`,	
 - `native int`,
 - `native float`,
 - `object`,
 - `managed pointer`.

Some opcodes such as the `NEG` which negates value on the stack behaves differently for different types.

The static analysis simulates the interpreter but only keeps track of what types are being put on the stack. Since we do not know the exact values on the stack we are unable to branch correctly and therefore we have to look through all options at least once. We still visit each opcode only once though. Before each brancjhing instruction we have to rembember the current stack state and the instruction to which we are supposed to jump next. This branche exploring is done in a depth-first search manner.

Some more complexity is brought by handling exceptions. That can be actually solved pretty easily as we first explore the code without exceptions and only then we explore the exception handlers - `catch` clauses. Although we have to be carefull with the `finally` clasuses and make sure that we do not explore anything twice and perform the jumps correctly.

> Visualisation of the static analysis flow.
> 
> ![static analysis](img/static_analysis.png)

The implementation uses the charasteristic of a depth-first search. We first put in all entry points of the analysis starting with the exception handlers, then the very first opcode. Then in a loop we handle the opcode, get the following opcode which we push onto the visit stack if valid and continue as before. 

Handling of the opcodes is very straingth forward. Either we push some specific type onto the stack. For example with the `LDC.I4` we push `int32` onto the stack. With opcodes that require type information we first gather the types of the operands and then we push the result type onto the stack and mark the operand types in the result array. Note that the opcode types are gathered in an enum `OpCodeType`. That is because it is different from the `StackType` which is a list of types that are allowed to be on the stack. The `OpCodeType` is an extension of that as some opcodes allow mix use of two different operands and we have to keep track of both of them. Therefore opcode type such as `Int64_Int32` denoting two operands one of stack type `int64` and the other of type `int32` is possible.

This method allows us to perform CIL verification as well. The *Partition III CIL 1.5* specifies which operands are allowed for each opcode.


#### Stub methods and STDLIB

The standard library defines some methods as internal, which means that the implementation is provided by .NET runtime.
Since we interpret just the standard library, we have to provide an implementation for them in our runtime.

For this purpose, we created a mechanism for providing an implementation of these methods.
Whenever we are resolving a method and creating its `CILOSTAZOLRootNode`,
we can choose between a regular `CILMethodNode` or `CILRuntimeSpecificMethodNode`.
Whereas `CILMethodNode` features the regular loop for interpreting CIL instructions, `CILRuntimeSpecificMethodNode`
refers to a function, which provides an implementation of the method.

> Overview of stub methods
>
> ![stub_methods](./img/STUB.png)

The implementation, represented by `Function<VirtualFrame, Object>`, references a static function that similarly to the
`CILMethodNode` accepts a frame and returns an object.
Inside the function, we can use the API of `CILOSTAZOLFrame` to get the arguments of the method and return the result.
The API is minimal and contains just the necessary parameters for implementing the method.
If we need to allocate objects or perform similar complex operations,
we can use the `CILOSTAZOLContext` to get the necessary services.

Whenever a method is missing an implementation or needs a custom implementation, we change its node to a
`CILRuntimeSpecificMethodNode`.

A method is missing an implementation whenever its Relative Virtual Address (RVA) is zero.
As a result, we cannot interpret the method, since we don't know its instructions.
This can happen when the method has a `MethodImplOptions.InternalCall` attribute and refers to a method, which is
implemented by the runtime.
In this case, we have to create our own implementation of the method.
Many performance-critical methods are implemented this way.
Below is an example of some of many methods from the `System.Math` class, which are implemented this way.

```csharp
[Intrinsic]
[MethodImpl(MethodImplOptions.InternalCall)]
public static extern double Cos(double d);

[Intrinsic]
[MethodImpl(MethodImplOptions.InternalCall)]
public static extern double Cosh(double value);

[Intrinsic]
[MethodImpl(MethodImplOptions.InternalCall)]
public static extern double Exp(double d);

[Intrinsic]
[MethodImpl(MethodImplOptions.InternalCall)]
public static extern double Floor(double d);
```

Other times, we might come across a method, which has a body that could be interpreted, but we want to provide a custom
implementation.
A good example of this are IO methods, which use threading, culture, and other features,
which are not supported by our interpreter yet.
Below is an example of how the `System.Console` class initializes its output stream,
which is a static property and *must* be initialized before it is used.
The example uses `Monitor` and `Volatile` classes, which are not supported by our interpreter yet.

```csharp
public static TextWriter Out
{
    get
    {
        // Console.Out shouldn't be locked while holding a lock on s_syncObject.
        // Otherwise there can be a deadlock when another thread locks these
        // objects in opposite order.
        //
        // Some functionality requires the console to be initialized.
        // On Linux, this initialization requires a lock on Console.Out.
        // The EnsureConsoleInitialized call must be placed outside the s_syncObject lock.
        Debug.Assert(!Monitor.IsEntered(s_syncObject));

        return Volatile.Read(ref s_out) ?? EnsureInitialized();

        static TextWriter EnsureInitialized()
        {
            lock (s_syncObject) // Ensures Out and OutputEncoding are synchronized.
            {
                if (s_out == null)
                {
                    Volatile.Write(ref s_out, CreateOutputWriter(ConsolePal.OpenStandardOutput()));
                }
                return s_out;
            }
        }
    }
}
```

Although we created a mechanism for providing a custom implementation of standard library methods, we didn't implement
all of them.
We also use this mechanism to provide an implementation of methods, which are used in our benchmarks and use unsupported
CIL features.

The programmer can implement the functions for handling missing methods in any file and then register them in the
`RuntimeSpecificMethodImplementations` class.
There, a map of implemented methods is stored.
Currently, we use the string representation of the method signature as a key.
While this is not the most efficient way, it is the easiest to implement.
Moreover, the resolution of the method is done only once, so it doesn't greatly affect the performance of the
interpreter.

#### Nodeization

Nodeization is a process where we wrap the functionality of an instruction to executable node, store it, and patch the
CIL code by our custom opcode for invoking the stored node.
This process enables Truffle to cache static data required by the instruction for the next evaluation.

> Overview of nodeization
>
> ![nodeization](./img/Nodeization.png)

We created three nodeized instructions: `CALLNode`, `NEWOBJNode`, and `JMPNode`.

#### OSR

OSR offers a way to switch from the interpreter to the compiled code mid-method execution when a hot path is detected.
For AST interpreters, Truffle offers a way of doing this for *free*.
The programmer just has to implement certain nodes when working on loops and conditional statements.
For bytecode interpreters, the programmer has to implement a few more things.

OSR is done by implementing the `BytecodeOSRNode` interface.
This interface offers methods for us to override that can enable OSR to be triggered and to pass data to the compiled
code.

We are required to check every jump to the instruction to an instruction pointer that is less than the current one (a
*back-edge*) and attempt to do OSR if it makes sense in the given context.
Since the logic of checking back-edges is the same for all the jump instructions, we implemented
a `beforeJumpChecks(VirtualFrame frame, int curBCI, int targetBCI, int top)` method.
Should this method encounter a back-edge, it reports it using `BytecodeOSRNode::pollOSRBackEdge`.
The return value of `pollOSRBackEdge` indicates whether the OSR should be attempted.
If it should, we do so by calling `BytecodeOSRNode::tryOSR` and passing in the current state.
From what is available in the `beforeJumpChecks`, we are interested in the target instruction pointer, the frame, and
the top of the stack.

It is important that the used state (the top-stack pointer, target instruction pointer, etc.) is a PE constant.
We check that throughout the dispatch loop using `CompilerAsserts.partialEvaluationConstant(int value)`

It is also possible to pass in handlers and other data, but did not find a use for it.
Usually, passing in a handler to confirm that the OSR is indeed taking place is a good idea.
Due to how our tests are set up, we did not need to do this—we simply enable compilation details and get the
confirmation of OSR taking place from the logs.
The easiest way of checking whether the OSR took place is to measure the execution time of a hot loop.
In one such example, the `OSRTests::test`, described below, we measure the execution time of a loop doing arithmetic
operations that is executed 100 million times.

```csharp
 int i = 0;
 while (i < 100000000)
 {
       i = i + 1 + 2 / 2 + 1 + 3 + 4 * 5 / 6 * 7 
         + 8 - 9 + 10 - 35;
 }
 return i;
```

The measured speedup when using OSR of over 30x confirms that the OSR is indeed taking place to some extent.
The effect and efficiency of OSR is highly dependent on the code being executed and the PE-friendliness of the
interpreter.
Moving forward, the interpreter should be made more PE-friendly to enable OSR to be even more efficient.

### Launcher

We inherited the abstract `AbstractLanguageLauncher` class to make a custom `CILOSTAZOLLauncher` launcher which
evaluates the given `.dll` file.

The launcher allows us to have control over the engine options and the language options.
The `AbstractLanguageLauncher` class provides methods for override that allow us to parse the command-line arguments, 
print the help message, and create the language context.
We use these methods to extract the path to the `.dll` file from command-line arguments and print messages similar 
to the ones provided by the `dotnet` CLI.

Although the CILOSTAZOL engine options are defined in the `language` module, we list defined options here because of
their straight relation to the launcher.
While we could define multiple options for the launcher,
we decided to use only one option for the path to the `.dll`, which is essential in order to run the program.
Other options could include logging or debugging options, but we did not find a need for them.

| Option          | Description                                                   |
|-----------------|---------------------------------------------------------------|
| cil.libraryPath | Describes additional path containing .NET standard libraries. |

Additionally, the launcher measures the execution time of the program
and prints it to the standard error stream together with the return code.
This was first implemented in BACIL and left in the CILOSTAZOL launcher as it is a useful feature for separating the 
time spent in the interpreter from the time spent compiling C# sources when running tests.

## Tests

In the following sections we will describe how we tested our interpreter and what we tested.

### Own tests

Tests are divided into two categories. One that requires the whole interpreter to run and one that can run without the
interpreter. Neither of those set of tests is unit tests as that would test only very small parts, which are
insufficient
for our purposes.

Tests that do not require the interpreter are much easier to test as we can inspect parsed and computed values on the
objects directly. For tests that do require the whole interpreter run, we are left with two options. We can inspect the
return code of the program or the standard output. Both options require a significant amount of implementation to work
properly. In the first part of the project, we naturally used smaller tests that did not require the interpreter.

As we are developing an interpreter that works with CIL, we are faced with the challenge of obtaining CIL code that we
can test.
We have decided to use C# as a language for writing tests as it is the most natural choice.
In order to validate that the written C# code produces the CIL opcodes that we expect,
we extensively used the JetBrains decompiler and SharpLab tool.
This way, we can check what CIL code is produced by the C# code we have written and navigate the state of the execution
of the interpreter much more easily.

Since each test requires compiled C# code that it can test, we have created three different approaches to make writing
tests as easy and pleasant as possible as well as stay reasonably efficient while debugging problems.

#### Test from dll

First approach requires to have compiled dll file available before running the tests. Test targets themselves are
gathered in a solution that is compiled using a script so that it can be automated. This approach is the fastest as we
do not waste much time on compiling the C# code before each test execution and is therefore well suited for debugging.
This approach is heavily utilised in the batch of tests that do not require interpreter and test the parser and other
parts such as generic type substitution.

These tests are located in the `language` module. Each batch of tests has its own project. For these tests we don't need
executable dlls with entrypoint `Main` method as we are most interested only in parsing. Therefore, we can write
multiple test targets in one project, which is convenient.

Down-sight of this approach is that you have to have another window open to see the C# code you are testing.

#### Test from code

The second approach is to write the C# code directly in the test.
While developing in IntelliJ, we can even get some basic syntax highlighting thanks to the IntelliJ string annotations.
This code is then copied into a file in a temporary
directory and only then compiled on demand. Test targets that require an entry point must be each implemented in its
own assembly.

The main advantage is fast test writing as one does not have to leave one file and can just keep writing. With top-level
statements, there is very little overhead code. The downside is that the compilation takes a lot of time. When
debugging,
we have opted for the first testing method, but for the convenience of writing tests, we have kept this approach for
most
of the tests.

We ended up using this approach for most of the tests that require the interpreter to run located at the `test` module.
The first approach was too slow and tedious.

#### Test from file

The third approach combines the worst of the previous two. You write the C# code to a specific file, therefore, you can
not see it and have to switch windows while writing tests, and you also have to wait before it compiles.
We ended up not using this approach at all apart from the example tests we wrote for this method in the `TestTemplates`
class.

In the `TestBase` class which implements helper methods for compiling and running the interpreter we have helper methods
for the launcher itself for integration tests. To run launcher, we have to set up paths to the standard library. The
launcher itself is not very configurable, therefore, we would not be able to execute the program's output, which is one
of the
very few ways we can test the whole system. Templates utilising the launcher are marked as deprecated due to exactly
those reasons, and it is recommended to use templates that evaluate the context directly.

### Pipeline

We have automated all the tests in our pipeline which ran on every merge request together with java format check. Since
the compilation of tests took a significant amount of time to complete, we have divided the pipeline into several steps:

- format check,
- compilation of the interpreter,
- compilation of the test targets,
- execution of the tests.

This way, we had a feedback provided in episodes that allowed us to work on fixes for each step of the pipeline
individually.

### Benchmark game

Inspired by the BACIL thesis, we decided to benchmark our implementation on arithmetic-heavy programs.
A suite recommended to us by the supervisors is
the benchmark game [[18]](https://benchmarksgame-team.pages.debian.net/benchmarksgame/).
This community-driven project aims to provide a set of benchmarks for various programming languages.

#### Benchmarking methodology

We took a sample of six benchmarks from the suite and compared the performance of our interpreter to the performance of
.NET 7.
The sample was chosen based on its required features.
Some benchmarks use AVX instructions, which are not supported by our interpreter.
Furthermore, there were additional intrinsics that we omitted at the time of writing the specification.
The benchmarks had to be further simplified to be compatible with our interpreter.
These simplifications are almost entirely related to the lack of support for threads and tasks; however, some simple
functionalities were also omitted.
For example, formatted output and string interpolation were replaced with string concatenation.

Due to the fact that the benchmarks were stripped of multithreading, the performance of .NET 7 greatly differs from the
results shown on the benchmark game website.
With some benchmark runs taking over 30 seconds in .NET 7 release mode, we anticipated that our interpreter would be
much slower and decided to limit the number of iterations to three, though any arbitrary number could be chosen.

We decided not to compare our interpreter to BACIL, as it was never our goal to outperform it.
Instead, we wanted to compare our interpreter to the .NET runtime, as it is the most popular implementation of the
Common Language Infrastructure, and with recent releases, it has become a viable option for high-performance
applications.
Moreover, attempting to benchmark BACIL would require a lot of effort, as its functionality is limited, and it does not
support many of the features that are required by the benchmarks. We believe that the benchmarks executed on BACIL in
the past might have been greatly simplified.

#### Benchmarking script

Since the development of the project took place on a variety of machines, we decided to create a Python script that
would automate the benchmarking process.
We believe that Python is a good choice when attempting to create a script that is supposed to be portable.
Due to time constraints, we did not cover the Windows platform.
However, due to the choice of packages, we believe that the script should work with little tinkering on Windows as well.

The script is located in the benchmarking repository [[19]](https://github.com/Softwarovy-projekt/TestsAndBenchmarks),
together with the test projects.
It accepts the following arguments:

```
  --cilostazol <Path to the CILOSTAZOL launcher>
  --cilostazolLanguage <Path to the CILOSTAZOL language>
  --dotnet <Path to the .NET runtime> (Default: dotnet)
  --dotnetLibrary <Path to the .NET library> (E.g., Microsoft.NETCore.App/x.y.z)
  --benchmarks <Path to the benchmarks> (Default: ../Benchmarks)
```

The user provides the paths to both .NET and CILOSTAZOL, as well as the path to the benchmarks.
For CILOSTAZOL, there are two additional specific paths that need to be provided.
The path to CILOSTAZOL itself is the path to the launcher, which is used to run the benchmarks.
This launcher is generated by Maven as *launcher.jar.*
The path to the CILOSTAZOL language is the path to the *language* jar, which is as shaded jar containing the language
implementation and the parser.
This jar is generated by Maven as *cil-language.jar*.
The path to .NET libraries is the path to the directory containing the .NET runtime, namely the system libraries, such
as *System.Runtime.dll*.

This way, the user can experiment with different versions of .NET and CILOSTAZOL.
The script then runs the benchmarks and outputs summaries to the standard output.

After cleaning the solution, the script compiles the benchmarks in the release mode.
Executables are then collected and run with both .NET and CILOSTAZOL.
As stated above, we run three iterations of each benchmark.
Standard output and standard error are redirected to `/dev/null` to avoid any overhead.
The validation of the output is done when running tests in Maven, where the same benchmarks are run with small inputs.

During each run, we measure the elapsed time and the memory usage.
We do so by running the benchmark in a separate process and probing it from another thread.
The elapsed time is measured using the *time* package and corresponds to the wall-clock time.
We also measure the time spent in the user mode and kernel mode.

The memory usage is measured using the *psutil* package.
We probe the process and its children every 100ms (configurable) and record the maximum memory usage of the given run.

Lastly, CPU usage is measured using the *psutil* package as well.
The result is a percentage of CPU usage for each core/thread.

The elapsed time and memory usage are then averaged over the three iterations, while the CPU usage is reported for the
middle iteration.

The output is in the following format:

```
Benchmark [CILOSTAZOL] binarytrees-2.dll:
	Average elapsed time [s]: 209.10286704699197
	Average memory usage [kB]: 318340.1666666667
	CPU usage mid-run [%]: 30% 28% 24% 22% 91% 84% 25% 13%
	Max memory usage [kB]: 488770.5
```

This is an output for the *binarytrees* benchmark running in the provided CILOSTAZOL launcher.

#### Results

The following results were taken on a machine with an Apple M1 chip with 4 performance cores and 4 efficiency cores and
16GB of LPDDR4X-4266 MHz running macOS 13.5 (22G74).
For this ARM-based chip, we used the aarch64 version of .NET 7.0.2 and the aarch64 version of Oracle GraalVM for JDK
17.0.8.

> Performance comparison against .NET 7.0.2 on Apple M1
>
> ![performance](./img/Performance.svg)

The results show that our interpreter is significantly slower than .NET 7 when executing both release and debug builds.
This might be due to a variety of factors.
Parsing metadata on demand implies that we cannot perform PE to a great extent.
Furthermore, other than OSR, we did not implement any explicit optimizations.
While BACIL showed more promising results, we now know the level of technical debt that it carried and the corners that
had to be cut in order to show great performance.

> Memory usage comparison against .NET 7.0.2 on Apple M1
>
> ![memory](./img/Memory.svg)

Memory usage of CILOSTAZOL was very consistent across all benchmarks.
It usually as in the range of 100-130MB, even for the smallest benchmarks.
.NET 7, on the other hand, showed a much more varied memory usage.
It managed to keep the memory usage low when possible, hovering around 4MB.
On more intensive tasks, the memory usage would double to around 8-10MB.
This shows how mature the .NET runtime is and how much effort has been put into optimizing it for workloads such as
serverless computing.

## Development process

CILOSTAZOL was developed in a team of three members - Tomáš Husák, Denis Leskovar, Jan Kleprlík in cooperation with
Štěpán Šindelář providing helpful technical consultations and supervised by Tomáš Petříček.

The development process started with heavy analysis of the problem domain and an existing solution.

Even though the work on the project was initially slow, we managed to hold weekly meetings every Thursday throughout
the whole period to discuss the progress, problems and plans for the next week.

For collaboration, we have initially used Trello to keep track of tasks and their progress. This has turned out not to
be
very effective as none of the team members used the tool outside of the project. We have then switched to GitHub where
we kept track of research progress, insights as well as the tasks themselves. Both for the research and implementation
part of this project.

For the initial research, we even consulted with the author of BACIL - Jan Gocník.

Team communication was done via Messenger app and Google-meets as every team member was available on those platforms
most of the time.

In order to keep the programming standard at a reasonable level early in the development, we unified the development
environment to IntelliJ IDEA, set up automatic java-formatting and set up a pipeline that would verify this for us. at
the beginning of the development process, we have agreed to push directly into master due to several reasons:

- the first issue could not be easily separated into smaller tasks,
- working on the first issue meant changing bits of code all over the place,
- none of the team members was yet very familiar with the code base,
- there weren't any tests that could verify the correctness.
  This approach turned out to be a good step forward as it incentives us to more frequent discussions about what we do
  and where we want to make changes, how well we understand the codebase and what architectural ideas do we have for the
  next issues.

As soon as we've reached a point where problems could be divided into reasonably big issues, we have switched to a more
traditional approach of creating a branch for each task and merging it into master via a pull request. Although we have
still often switched to messaging or online calls when some questions or notes arose during reviews. The workload was divided among team members based on their interests. Usually two people were working together on one feature which was blocking other progress. The third was working on his a different non-blocking feature that was independent of others.

## Feature improvements

The next step would be support type and accessibility checking which need to use already parsed metadata and add checkers into methods handling instructions in `CILMethodNode`.

We didn't investigate threads, although it would be needed to implement native calls and probably implement some internal methods provided by the .NET runtime itself.

We didn't investigate native calls as well, although it could be done by invoking Java JNI or in the case of uncommon conventions, providing our own trampolines implemented in C++ and calling it from Java.

To be able to fully use the standard library, all CIL constructs have to be supported. It means to also support nested classes, properties, method semantics, etc. which is out of the scope of this work.
However, adding mentioned constructs to the current type system shouldn't be difficult since our symbols system was designed to be extendible from the start. 

## Conclusion

Over the course of the last nine months, we have been working as a team on an interpreter for CIL. 
Since CIL and CLI are topics we are all interested in, we tried to make the interpreter as modern as possible and fill 
it with features we are passionate about.

Implementing a complex type system, which is a core part of the interpreter, was a great learning experience.
It showed us the intricacies of CLI and how Roslyn and .NET handle them.

Being able to work on static analysis for resolving stack types ahead of time is another highlight of our effort,
as it was a more sophisticated approach to interpreting CIL than what we have seen in other interpreters,
including some of the first .NET Core versions.

As a team, we faced difficult decisions early on.
We decided to tackle the technical depth of the project we were building on and rewrite the parser.
This gave us a strong foundation for the rest of the project, but it also meant that we had to spend a lot of time
on the parser and the type system, a task that was not originally planned.

Even with such set backs, we have managed to implement critical functionality, and we are now able to run much more 
complex programs than we were able to at the beginning of the project with BACIL.
We have managed to extend the CIL parser to correctly read and store metadata, making it possibly the most complete 
Java-based CIL parser.
During this time, we have overhauled the type system to support generic types and their substitution.

The next natural step was to adopt the static object model provided by Truffle and use it for allocations and property
accesses, making the interpreter safer and more efficient.
The remaining time was spent on implementing the interpreter itself, which was a straightforward task thanks to previous 
work.
We added support for most of the CIL instructions and successfully covered those that were in scope for this project.

After seeing an opportunity to use static analysis to improve the performance of the interpreter, we have implemented
a meta interpreter which was originally out of scope for this project.
We then leveraged OSR support that Truffle offers to improve the performance of the interpreter even further.

All this was done while practicing good software engineering practices, such as code reviews, unit testing, and
continuous integration. Because all team members come form C# background we used to have tendencies to write the Java 
code in a C# like manner. To prevent this, we have set up a pipeline that would verify the code style and formatting 
and refactored the code to follow the Java conventions.
We were able to push new functionality faster due to working pipelines that we set up during the start of the project.
We have also created a benchmarking script that allowed us to compare the performance of our interpreter to the .NET
runtime.
This script, together with other tools we have not explored yet, could provide us with means to systematically improve 
the performance of the interpreter in the future.

## Appendix

### Overview of promised features

We set a list of features that we wanted to accomplish in the specification.
We provide an overview of completed features and give a reason for those ones, we didn't make.

| Task | State | Note |
| --- | --- | --- |
| 0.0.0 | Completed | We didn't do CIL code inlining because it is voluntary and we had to deal with other problems which occurred during implementation. |
| 0.0.1 | Completed | - |
| 0.0.2 | Not completed | It is voluntary and we had to deal with other problems which occurred during implementation.
| 0.0.3 | Completed | We were able to interpret standard library exceptions and use them. However, runtime information stored in the exceptions was out of the scope of this work because of other unsupported features used by them. |
| 0.0.4 | Completed | - |
| 0.0.5 | Completed | - |
| 0.1.0 | Completed | - |
| 0.1.1 | Almost completed | We don't support the `decimal` representation. |
| 0.1.2 | Completed | - |
| 1.0.0 | Completed | - |
| 1.0.1 | Completed | - |
| 1.0.2 | Completed | - |
| 1.0.3 | Completed | - |
| 1.0.4 | Completed | - |
| 1.0.5 | Completed | - |
| 1.1.0 | Not completed | Unexpected problems with different parts of the project. |
| 1.1.1 | Not completed | Unexpected problems with different parts of the project. |
| 1.1.2 | Not completed | Unexpected problems with different parts of the project. |
| 1.1.3 | Not completed | Unexpected problems with different parts of the project. |
| 1.2.0 | Completed | - |
| 1.2.1 | Completed | - |
| 1.2.2 | Not completed | It is voluntary and we had to deal with other problems which occurred during implementation. |

As you can see, we completed almost all promised features, which were not voluntary.
There are two exceptions.

We decided to not do *Polyglot module* because there were unexpected problems with the parser.
Even before the implementation, we asked the initial author of BACIL where can arise potential problems and the parser was not part of it.
In the end, the parser and type system were major parts, which took us more time than we expected.
Although, we don't think we could do better time estimation in the time when we investigated BACIL and promised features.
Because of these issues, we didn't make polyglot API, which can be considered *nice-to-have* feature and doesn't have a significant influence on other parts of the implementation.

`decimal` value was not implemented because there was no exact mapping between this type and Java primitive type. It is not impossible to make it work; however, we had to solve other unexpected problems with the parser. 

### List of supported opcodes


| Opcode | Supported | | Opcode | Supported | | Opcode | Supported | | Opcode | Supported |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| `nop` | OK || `break` | OK || `ldarg.0` | OK || `ldarg.1` | OK |
| `ldarg.2` | OK || `ldarg.3` | OK || `ldloc.0` | OK || `ldloc.1` | OK |
| `ldloc.2` | OK || `ldloc.3` | OK || `stloc.0` | OK || `stloc.1` | OK |
| `stloc.2` | OK || `stloc.3` | OK || `ldarg.s` | OK || `ldarga.s` | OK |
| `starg.s` | OK || `ldloc.s` | OK || `ldloca.s` | OK || `stloc.s` | OK |
| `ldnull` | OK || `ldc.i4.m1` | OK || `ldc.i4.0` | OK || `ldc.i4.1` | OK |
| `ldc.i4.2` | OK || `ldc.i4.3` | OK || `ldc.i4.4` | OK || `ldc.i4.5` | OK |
| `ldc.i4.6` | OK || `ldc.i4.7` | OK || `ldc.i4.8` | OK || `ldc.i4.s` | OK |
| `ldc.i4` | OK || `ldc.i8` | OK || `ldc.r4` | OK || `ldc.r8` | OK |
| `dup` | OK || `pop` | OK || `jmp` | OK || `call` | OK |
| `calli` | X || `ret` | OK || `br.s` | OK || `brfalse.s` | OK |
| `brtrue.s` | OK || `beq.s` | OK || `bge.s` | OK || `bgt.s` | OK |
| `ble.s` | OK || `blt.s` | OK || `bne.un.s` | OK || `bge.un.s` | OK |
| `bgt.un.s` | OK || `ble.un.s` | OK || `blt.un.s` | OK || `br` | OK |
| `brfalse` | OK || `brtrue` | OK || `beq` | OK || `bge` | OK |
| `bgt` | OK || `ble` | OK || `blt` | OK || `bne.un` | OK |
| `bge.un` | OK || `bgt.un` | OK || `ble.un` | OK || `blt.un` | OK |
| `switch` | OK || `ldind.i1` | OK || `ldind.u1` | OK || `ldind.i2` | OK |
| `ldind.u2` | OK || `ldind.i4` | OK || `ldind.u4` | OK || `ldind.i8` | OK |
| `ldind.i` | OK || `ldind.r4` | OK || `ldind.r8` | OK || `ldind.ref` | OK |
| `stind.ref` | OK || `stind.i1` | OK || `stind.i2` | OK || `stind.i4` | OK |
| `stind.i8` | OK || `stind.r4` | OK || `stind.r8` | OK || `add` | OK |
| `sub` | OK || `mul` | OK || `div` | OK || `div.un` | OK |
| `rem` | OK || `rem.un` | OK || `and` | OK || `or` | OK |
| `xor` | OK || `shl` | OK || `shr` | OK || `shr.un` | OK |
| `neg` | OK || `not` | OK || `conv.i1` | OK || `conv.i2` | OK |
| `conv.i4` | OK || `conv.i8` | OK || `conv.r4` | OK || `conv.r8` | OK |
| `conv.u4` | OK || `conv.u8` | OK || `callvirt` | OK || `cpobj` | OK |
| `ldobj` | OK || `ldstr` | OK || `newobj` | OK || `castclass` | OK |
| `isinst` | OK || `conv.r.un` | OK || `unbox` | OK || `throw` | OK |
| `ldfld` | OK || `ldflda` | OK || `stfld` | OK || `ldsfld` | OK |
| `ldsflda` | OK || `stsfld` | OK || `stobj` | OK || `conv.ovf.i1.un` | OK |
| `conv.ovf.i2.un` | OK || `conv.ovf.i4.un` | OK || `conv.ovf.i8.un` | OK || `conv.ovf.u1.un` | OK |
| `conv.ovf.u2.un` | OK || `conv.ovf.u4.un` | OK || `conv.ovf.u8.un` | OK || `conv.ovf.i.un` | OK |
| `conv.ovf.u.un` | OK || `box` | OK || `newarr` | OK || `ldlen` | OK |
| `ldelema` | OK || `ldelem.i1` | OK || `ldelem.u1` | OK || `ldelem.i2` | OK |
| `ldelem.u2` | OK || `ldelem.i4` | OK || `ldelem.u4` | OK || `ldelem.i8` | OK |
| `ldelem.i` | OK || `ldelem.r4` | OK || `ldelem.r8` | OK || `ldelem.ref` | OK |
| `stelem.i` | OK || `stelem.i1` | OK || `stelem.i2` | OK || `stelem.i4` | OK |
| `stelem.i8` | OK || `stelem.r4` | OK || `stelem.r8` | OK || `stelem.ref` | OK |
| `ldelem` | OK || `stelem` | OK || `unbox.any` | OK || `conv.ovf.i1` | OK |
| `conv.ovf.u1` | OK || `conv.ovf.i2` | OK || `conv.ovf.u2` | OK || `conv.ovf.i4` | OK |
| `conv.ovf.u4` | OK || `conv.ovf.i8` | OK || `conv.ovf.u8` | OK || `refanyval` | OK |
| `ckfinite` | X || `mkrefany` | OK || `ldtoken` | X || `conv.u2` | OK |
| `conv.u1` | OK || `conv.i` | OK || `conv.ovf.i` | OK || `conv.ovf.u` | OK |
| `add.ovf` | OK || `add.ovf.un` | OK || `mul.ovf` | OK || `mul.ovf.un` | OK |
| `sub.ovf` | OK || `sub.ovf.un` | OK || `endfinally` | OK || `leave` | OK |
| `leave.s` | OK || `stind.i` | OK || `conv.u` | OK || `arglist` | X |
| `ceq` | OK || `cgt` | OK || `cgt.un` | OK || `clt` | OK |
| `clt.un` | OK || `ldftn` | X || `ldvirtftn` | X || `ldarg` | OK |
| `ldarga` | OK || `starg` | OK || `ldloc` | OK || `ldloca` | OK |
| `stloc` | OK || `localloc` | X || `endfilter` | X || `unaligned.` | X |
| `volatile.` | X || `tail.` | X || `initobj` | OK || `constrained.` | X |
| `cpblk` | X || `initblk` | X || `no.` | X || `rethrow` | OK |
| `sizeof` | OK || `refanytype` | OK || `readonly.` | X |

### User guide

#### Prerequisites

There are two main ways of running CILOSTAZOL.
Firstly, one can run CILOSTAZOL on GraalVM, which is the recommended way.
Secondly, one can run CILOSTAZOL on stock JDK.

The latter case is simpler.
One only needs to have Java 17 installed and recognized by Maven.
Truffle dependencies are then downloaded automatically.

The former case requires GraalVM to be installed.
GraalVM can be downloaded from the GraalVM website [[20]](https://www.graalvm.org/downloads/) or installed using SDKMAN.
The current available version for Java 17 is *Oracle GraalVM 17.0.8*, although before changing the versioning scheme, 
the version used for development was *Oracle GraalVM 22.3.0*.

The downloaded JDK works as any other.
If the user has properly set up the JAVA_HOME environment variable, the JDK is automatically recognized.
It can be checked by running `java --version` from the terminal.
The output should look like this:

```
java version "17.0.8" 2023-07-18 LTS
Java(TM) SE Runtime Environment Oracle GraalVM 17.0.8+9.1 (build 17.0.8+9-LTS-jvmci-23.0-b14)
Java HotSpot(TM) 64-Bit Server VM Oracle GraalVM 17.0.8+9.1 (build 17.0.8+9-LTS-jvmci-23.0-b14, mixed mode, sharing)
```

Or like this for older versions:

```
java 17.0.4 2022-07-19 LTS
Java(TM) SE Runtime Environment GraalVM EE 22.2.0 (build 17.0.4+11-LTS-jvmci-22.2-b05)
Java HotSpot(TM) 64-Bit Server VM GraalVM EE 22.2.0 (build 17.0.4+11-LTS-jvmci-22.2-b05, mixed mode, sharing)
```

The selected build system is Maven.
Maven can be installed using the package manager of the user's operating system or downloaded from the
Maven website [[21]](https://maven.apache.org/download.cgi).
The version used for development was *Apache Maven 3.8.5*.
Ensure that Maven is using your preferred JDK by running `mvn --version` from the terminal.

In order to run tests, one should have .NET installed.
The version used for development was .NET 7.0.2, and we recommend using versions of .NET 7.
The .NET SDK can be downloaded from the Microsoft website [22](https://dotnet.microsoft.com/download/dotnet/7.0).
It is enough to download the runtime, the entire SDK is not needed. Unfortunately CILOSTAZOL is not yet very well configurable and therefore needs exactly the version 7.x.x of .NET otherwise unexpected problems might occur.

To allow functionality of multi-dimensional arrays one also needs to compile the `CILOSTAZOLInternalImpl` project and include the dll in the same directory as the .NET runtime. This project can be found in `.\language\src\main\resources\CILOSTAZOLInternalImpl`.

Lastly, one needs to have Python 3 installed in order to run external benchmarks.
The version used for development was Python 3.10.6, but any version of Python 3 should work.
Packages needed for running benchmarks using the Python script are listed in the *requirements.txt* file in the given 
repository.

#### Running CILOSTAZOL

Once the user has selected his JDK preference, he can run CILOSTAZOL.
The source code is available in the *CILOSTAZOL* repository on GitHub [[23]](https://github.com/Softwarovy-projekt/Cilostazol).
The project is built using Maven, and it can be done by running `mvn package` from the root of the repository.
This will build the project and run all tests.
Note that running tests in the *tests* package takes up to 10 minutes.
The tests can be skipped by running `mvn package -Dmaven.test.skip`.

As a result, we get the following jar files:
- *launcher.jar* - the main jar file that can be used to run CILOSTAZOL
- *cil-language.jar* - the jar file containing the CILOSTAZOL language and its parser
- *cil-parser-1.0-SNAPSHOT.jar* - a jar file containing the parser for the CIL language, hidden to the user
- *tests-1.0-SNAPSHOT.jar* - a jar file containing the tests for the CIL language, hidden to the user

Maven does two types of shading.
First, the *cil-language.jar* provides the language and all its dependencies.
This is important as we will be providing the language as its own artifact.
Second, the *launcher.jar* provides the launcher and uses the *cil-language.jar* as a dependency.

The *launcher.jar* can be run using `java -jar <path>/launcher.jar`.
This by itself only prints the help message.
If we want to run a CIL program, we need to append *cil-language.jar* to the Truffle class path.
Running `java -Dtruffle.class.path.append=<path>/cil-language.jar -jar <path>/launcher.jar` now shows the CIL language 
support in the help message.

Finally, if we run `java -Dtruffle.class.path.append=<path>/cil-language.jar -jar <path>/launcher.jar --cil.libraryPath=<path>/Microsoft.NETCore.App/7.0.3/ <path>/nbody-2.dll`,
we successfully run the interpreter on the *nbody-2.dll* program.

This way, we parametrize the launch of the interpreter to allow for different versions of .NET and different versions 
of the interpreter using the same launcher.

The project can be opened in IntelliJ IDEA as a Maven project.
This way, the user can run the project from the IDE and debug it.
During development, this was the preferred way of running the project.

#### Running benchmarks

Our Python benchmark runner available on GitHub [[24]](https://github.com/Softwarovy-projekt/TestsAndBenchmarks) uses the 
commands described above to run benchmarks.

Similar to running from the command line, the user needs to specify the path to the launcher, the language, and .NET 
libraries.
Additionally, the script requires a path to the .NET runtime, which is used to run the benchmarks.

Below are the available options for the script:

```
--cilostazol <Path to the CILOSTAZOL launcher>
--cilostazolLanguage <Path to the CILOSTAZOL language>
--dotnet <Path to the .NET runtime> (Default: dotnet)
--dotnetLibrary <Path to the .NET library> (E.g., Microsoft.NETCore.App/x.y.z)
--benchmarks <Path to the benchmarks> (Default: ../Benchmarks)
```

After installing the necessary packages from the *requirements.txt* file, the script can be run using `python3 main.py`.
